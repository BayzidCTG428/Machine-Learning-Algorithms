{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 2: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 3: Load dataset\n",
        "DATA_PATH = '/content/drive/MyDrive/dataset/classification_data.csv'\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Step 4: Explore dataset\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df.iloc[:, -1].value_counts())\n",
        "\n",
        "# Step 5: Split features and target\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Step 6: Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Step 7: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 8: Euclidean distance function\n",
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "# Step 9: Weighted KNN classifier\n",
        "class WeightedKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_single(x) for x in X])\n",
        "\n",
        "    def _predict_single(self, x):\n",
        "        distances = np.array([euclidean_distance(x, xt) for xt in self.X_train])\n",
        "        k_idx = np.argsort(distances)[:self.k]\n",
        "        labels = self.y_train[k_idx]\n",
        "        weights = 1 / (distances[k_idx] + 1e-5)\n",
        "        vote = {}\n",
        "        for l, w in zip(labels, weights):\n",
        "            vote[l] = vote.get(l, 0) + w\n",
        "        return max(vote, key=vote.get)\n",
        "\n",
        "# Step 10: Train model\n",
        "k = 5\n",
        "model = WeightedKNN(k=k)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 11: Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 12: Evaluation metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "prec = precision_score(y_test, y_pred, average='weighted')\n",
        "rec = recall_score(y_test, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "# Step 13: Confusion matrix plot\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 14: ROC Curve & AUC (binary only)\n",
        "if len(np.unique(y)) == 2:\n",
        "    y_prob = np.array([1 / (1 + np.exp(-euclidean_distance(x, X_train.mean(axis=0)))) for x in X_test])\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0,1],[0,1],'--', color='grey')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(f\"AUC Score: {roc_auc:.4f}\")\n",
        "else:\n",
        "    print(\"ROC/AUC is only for binary classification\")\n"
      ],
      "metadata": {
        "id": "fXsnrmdZoyUO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}